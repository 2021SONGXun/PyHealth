{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj20/miniconda3/envs/pyhealth/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import UMLSDataset\n",
    "\n",
    "umls_ds = UMLSDataset(\n",
    "    root=\"https://storage.googleapis.com/pyhealth/umls/\",\n",
    "    dev=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=True):\n",
      "\t- Dataset: UMLSDataset\n",
      "\t- Number of triples: 88176\n",
      "\t- Number of entities: 9737\n",
      "\t- Number of relations: 8\n",
      "\t- Task name: Null\n",
      "\t- Number of samples: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "umls_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UMLSDataset base dataset from /home/pj20/.cache/pyhealth/datasets/46e7370273967c215741135e6ccdd2b9.pkl\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.tasks import link_prediction_fn\n",
    "\n",
    "umls_ds = umls_ds.set_task(link_prediction_fn, negative_sampling=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=True):\n",
      "\t- Dataset: UMLSDataset\n",
      "\t- Number of triples: 88176\n",
      "\t- Number of entities: 9737\n",
      "\t- Number of relations: 8\n",
      "\t- Task name: link_prediction_fn\n",
      "\t- Number of samples: 176352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "umls_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import split_by_keys, get_dataloader_kg\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = split_by_keys(umls_ds, [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70540"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset['head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_loader, num_batch_train = get_dataloader_kg(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader, num_batch_val = get_dataloader_kg(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader, num_batch_test = get_dataloader_kg(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models.kg import TransE, RotatE\n",
    "\n",
    "model = RotatE(\n",
    "    dataset=umls_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RotatE()\n",
      "Metrics: None\n",
      "Device: cuda:6\n",
      "\n",
      "Training:\n",
      "Batch size: 256\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: None\n",
      "Monitor: None\n",
      "Monitor criterion: max\n",
      "Epochs: 20\n",
      "\n",
      "Epoch 0 / 20: 100%|██████████| 100/100 [00:01<00:00, 79.10it/s]\n",
      "--- Train epoch-0, step-100 ---\n",
      "loss: 1.5616\n",
      "\n",
      "Epoch 1 / 20: 100%|██████████| 100/100 [00:01<00:00, 81.11it/s]\n",
      "--- Train epoch-1, step-200 ---\n",
      "loss: 0.8167\n",
      "\n",
      "Epoch 2 / 20: 100%|██████████| 100/100 [00:01<00:00, 78.95it/s]\n",
      "--- Train epoch-2, step-300 ---\n",
      "loss: 0.6330\n",
      "\n",
      "Epoch 3 / 20: 100%|██████████| 100/100 [00:01<00:00, 79.72it/s]\n",
      "--- Train epoch-3, step-400 ---\n",
      "loss: 0.4502\n",
      "\n",
      "Epoch 4 / 20: 100%|██████████| 100/100 [00:01<00:00, 81.36it/s]\n",
      "--- Train epoch-4, step-500 ---\n",
      "loss: 0.2979\n",
      "\n",
      "Epoch 5 / 20: 100%|██████████| 100/100 [00:01<00:00, 84.04it/s]\n",
      "--- Train epoch-5, step-600 ---\n",
      "loss: 0.1957\n",
      "\n",
      "Epoch 6 / 20: 100%|██████████| 100/100 [00:01<00:00, 90.28it/s]\n",
      "--- Train epoch-6, step-700 ---\n",
      "loss: 0.1282\n",
      "\n",
      "Epoch 7 / 20: 100%|██████████| 100/100 [00:01<00:00, 90.87it/s]\n",
      "--- Train epoch-7, step-800 ---\n",
      "loss: 0.1019\n",
      "\n",
      "Epoch 8 / 20: 100%|██████████| 100/100 [00:01<00:00, 90.77it/s]\n",
      "--- Train epoch-8, step-900 ---\n",
      "loss: 0.0835\n",
      "\n",
      "Epoch 9 / 20: 100%|██████████| 100/100 [00:01<00:00, 90.52it/s]\n",
      "--- Train epoch-9, step-1000 ---\n",
      "loss: 0.0706\n",
      "\n",
      "Epoch 10 / 20: 100%|██████████| 100/100 [00:01<00:00, 90.53it/s]\n",
      "--- Train epoch-10, step-1100 ---\n",
      "loss: 0.0610\n",
      "\n",
      "Epoch 11 / 20: 100%|██████████| 100/100 [00:01<00:00, 91.20it/s]\n",
      "--- Train epoch-11, step-1200 ---\n",
      "loss: 0.0507\n",
      "\n",
      "Epoch 12 / 20: 100%|██████████| 100/100 [00:01<00:00, 90.47it/s]\n",
      "--- Train epoch-12, step-1300 ---\n",
      "loss: 0.0440\n",
      "\n",
      "Epoch 13 / 20: 100%|██████████| 100/100 [00:01<00:00, 90.64it/s]\n",
      "--- Train epoch-13, step-1400 ---\n",
      "loss: 0.0388\n",
      "\n",
      "Epoch 14 / 20: 100%|██████████| 100/100 [00:01<00:00, 89.38it/s]\n",
      "--- Train epoch-14, step-1500 ---\n",
      "loss: 0.0351\n",
      "\n",
      "Epoch 15 / 20: 100%|██████████| 100/100 [00:01<00:00, 88.08it/s]\n",
      "--- Train epoch-15, step-1600 ---\n",
      "loss: 0.0320\n",
      "\n",
      "Epoch 16 / 20: 100%|██████████| 100/100 [00:01<00:00, 91.11it/s]\n",
      "--- Train epoch-16, step-1700 ---\n",
      "loss: 0.0290\n",
      "\n",
      "Epoch 17 / 20:  75%|███████▌  | 75/100 [00:00<00:00, 90.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model\u001b[39m=\u001b[39mmodel, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:6\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      6\u001b[0m     train_dataloader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m      7\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m      9\u001b[0m     \u001b[39m## num_batch=num_batch_train,\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m     num_batch\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     optimizer_params\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     12\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m1e-3\u001b[39;49m\n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/PyHealth/pyhealth/trainer.py:210\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_dataloader, val_dataloader, test_dataloader, epochs, optimizer_class, optimizer_params, optimizer_object, num_batch, batch_size, weight_decay, max_grad_norm, monitor, monitor_criterion, load_best_model_at_last)\u001b[0m\n\u001b[1;32m    208\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(data_iterator)\n\u001b[1;32m    209\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    211\u001b[0m loss \u001b[39m=\u001b[39m output[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    212\u001b[0m \u001b[39m# backward\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyhealth/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PyHealth/pyhealth/models/kg/kg_base.py:171\u001b[0m, in \u001b[0;36mKGEBaseModel.forward\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    168\u001b[0m pos_sample, neg_sample, subsampling_weight \u001b[39m=\u001b[39m inputs\n\u001b[1;32m    169\u001b[0m sample_batch \u001b[39m=\u001b[39m (pos_sample, neg_sample)\n\u001b[0;32m--> 171\u001b[0m neg_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc(sample_batch\u001b[39m=\u001b[39;49msample_batch, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mns \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39madv\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    174\u001b[0m     neg_score \u001b[39m=\u001b[39m (F\u001b[39m.\u001b[39msoftmax(neg_score \u001b[39m*\u001b[39m \u001b[39m1.0\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach() \u001b[39m*\u001b[39m F\u001b[39m.\u001b[39mlogsigmoid(\u001b[39m-\u001b[39mneg_score))\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/PyHealth/pyhealth/models/kg/rotate.py:59\u001b[0m, in \u001b[0;36mRotatE.calc\u001b[0;34m(self, sample_batch, mode)\u001b[0m\n\u001b[1;32m     56\u001b[0m     im_score \u001b[39m=\u001b[39m im_score \u001b[39m-\u001b[39m tail_im\n\u001b[1;32m     58\u001b[0m score \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([re_score, im_score], dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m score \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39;49mnorm(dim \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin\u001b[39m.\u001b[39mitem() \u001b[39m-\u001b[39m score\u001b[39m.\u001b[39msum(dim \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/miniconda3/envs/pyhealth/lib/python3.8/site-packages/torch/_tensor.py:638\u001b[0m, in \u001b[0;36mTensor.norm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    636\u001b[0m         Tensor\u001b[39m.\u001b[39mnorm, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, p\u001b[39m=\u001b[39mp, dim\u001b[39m=\u001b[39mdim, keepdim\u001b[39m=\u001b[39mkeepdim, dtype\u001b[39m=\u001b[39mdtype\n\u001b[1;32m    637\u001b[0m     )\n\u001b[0;32m--> 638\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mnorm(\u001b[39mself\u001b[39;49m, p, dim, keepdim, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyhealth/lib/python3.8/site-packages/torch/functional.py:1506\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1504\u001b[0m     _dim \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(ndim))\n\u001b[1;32m   1505\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1506\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mfrobenius_norm(\u001b[39minput\u001b[39;49m, _dim, keepdim\u001b[39m=\u001b[39;49mkeepdim)\n\u001b[1;32m   1507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mfrobenius_norm(\u001b[39minput\u001b[39m, _dim, keepdim\u001b[39m=\u001b[39mkeepdim, out\u001b[39m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "import torch\n",
    "\n",
    "trainer = Trainer(model=model, device='cuda:6')\n",
    "trainer.train(\n",
    "    train_dataloader=train_loader,\n",
    "    epochs=20,\n",
    "    batch_size=batch_size,\n",
    "    ## num_batch=num_batch_train,\n",
    "    num_batch=100,\n",
    "    optimizer_params={\n",
    "        'lr': 1e-3\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('pyhealth')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f21ceecfad7439d73e6e7f7545e9bd7612115ec3ef8110d0d62b8e2d47104e9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
